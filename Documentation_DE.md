# Dokumentation MLP Tool

Dieses Tool bietet eine grafische Schnittstelle zur Python-Bibliothek scikit-learn und kann verwendet werden, um einfache neuronale Netze der Klasse **Multilayer Perceptron** (MLP) f√ºr Regressionsprobleme zu trainieren.

## Theoretische Grundlagen

### Struktur

Auszug aus [Wikipedia](https://en.wikipedia.org/wiki/Multilayer_perceptron):

> Ein MLP besteht aus mindestens drei [Schichten](https://en.wikipedia.org/wiki/Layer_(deep_learning) "Schicht (deep learning)") von Knoten: einer Eingabe-[Schicht](https://en.wikipedia.org/wiki/Layer_(deep_learning) "Schicht (deep learning)"), einer versteckten [Schicht](https://en.wikipedia.org/wiki/Layer_(deep_learning) "Schicht (deep learning)") und einer Ausgabe-[Schicht](https://en.wikipedia.org/wiki/Layer_(deep_learning) "Schicht (deep learning)"). Mit Ausnahme der Eingabeknoten ist jeder Knoten ein Neuron, das eine nichtlineare [Aktivierungsfunktion](https://en.wikipedia.org/wiki/Activation_function "Aktivierungsfunktion") verwendet. [...] Es kann Daten unterscheiden, die nicht [linear separierbar]([Linear separability - Wikipedia](https://en.wikipedia.org/wiki/Linear_separability) "Linear separability") sind. [...]
> 
> Da MLPs voll vernetzt sind, verbindet sich jeder Knoten in einer Schicht √ºber ein bestimmtes Gewicht $\omega_{ij}$ mit jedem Knoten in der folgenden Schicht.

### Aktivierungsfunktionen

Die Ausgabe $f(x)$ jedes Neurons wird durch Abbildung seiner gewichteten Eing√§nge $x$ auf die Aktivierungsfunktion bestimmt. Um nichtlineares Verhalten zu modellieren, sind Aktivierungsfunktionen wie Tangens Hyperbolicus oder die Sigmoidfunktion notwendig.

Typische Aktivierungsfunktionen sind:

#### Linear

Die lineare Funktion bildet die Eing√§nge direkt auf den Ausgang der Neuronen ab.

$$
f(x)=x
$$

#### Tangens Hyperbolicus

Diese logistische Aktivierungsfunktion liegt im Bereich von -1 bis 1.

$$
f(x)=\text{tanh}(x)
$$

#### Sigmoid

Diese logistische Aktivierungsfunktion liegt im Bereich von 0 bis 1.

$$
f(x)=\frac{1}{1+e^{-1}}
$$

#### ReLu

Die rektifizierte lineare Einheitsfunktion ist gleich der linearen Funktion f√ºr Werte $x>0$ und ist gleich 0 f√ºr Werte $x<0$.

$$
f(x)=\text{max$(0,x)$}
$$

Diese Funktion wird h√§ufig in Deep Neural Networks verwendet, um dem Problem der verschwindenden Gradienten entgegenzuwirken, welches verhindert, dass Modelle effektiv lernen.

### Solver

MLPs verwenden einen Algorithmus namens [Backpropagation](https://en.wikipedia.org/wiki/Backpropagation), um den Gradienten der Verlustfunktion in Bezug auf jedes Gewicht durch die Kettenregel zu berechnen. Diese Gradienten sind dann f√ºr die Optimierer- (oder Solver-) Algorithmen verf√ºgbar, um die Gewichte nach jeder Trainingsepoche zu aktualisieren. Die verf√ºgbaren Optimierer unterscheiden sich hinsichtlich des Ansatzes, das globale Minimum im Parameter-Hyperspace auf eine effiziente Weise zu finden.

## Funktions√ºbersicht

### Dateieingabe

Die Trainings- und Testdaten werden als Excel-Dateien (.xlsx) eingelesen. Die Trainingsdaten werden verwendet, um das Modell mit der gegebenen Konfiguration zu trainieren. Das Modell wird dann auf die Testdaten angewendet, um seine Genauigkeit zu berechnen.

Die ersten Spalten enthalten die Eingabedaten, die letzte Spalte ist immer f√ºr die Ausgabedaten reserviert. Zeilen, die Zeichenketten enthalten, werden w√§hrend des Eingabevorgangs automatisch verworfen. Dateien, die weniger als zwei Spalten enthalten, werden verworfen, ebenso wie Dateien mit nicht √ºbereinstimmender Spaltenanzahl.

Nach dem Laden eines Datensatzes wird eine Datenvorschau in der Konsole ausgegeben.

### Skalierer

Wenn der Datensatz noch nicht im Bereich von 0-1 liegt, werden durch Aktivieren dieser Option alle Werte der Trainingsdaten so skaliert, dass sie in den Bereich von 0-1 passen und der Faktor und der Minimalwert werden auf der Konsole ausgegeben. Diese Werte k√∂nnen dann in anderer Software verwendet werden, um die Ausgabewerte wieder auf den urspr√ºnglichen Bereich zu skalieren.

### Konfiguration

Die folgenden Parameter k√∂nnen konfiguriert werden:
(siehe [scikit-learn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html) f√ºr weitere Informationen)

- **Aktivierungsfunktion:**
  Die mathematische Funktion, mit der die Ausgabe des Neurons auf der Grundlage seiner Eingabe bestimmt wird. Verf√ºgbare Funktionen sind:
  
  - ReLu: die rektifizierte lineare Einheitsfunktion, $f(x)=max(0, x)$
  - TanH: Tangens Hyperbolicus, $f(x)=tanh(x)$
  - Linear: $f(x)=x$
  - Sigmoid: logistische Sigmoidfunktion, $\frac{1}{1+e^{-x}}$

- **Solver:**
  Der Lernalgorithmus, der zur Aktualisierung der Verbindungsgewichte nach jeder Epoche verwendet wird.
  Verf√ºgbare Solver sind:
  
  - [Adam](https://arxiv.org/abs/1412.6980): Adaptive Moment Estimation. Speichert den exponentiell abfallenden Durchschnitt der vergangenen quadratischen Gradienten und die Gradienten zur adaptiven Berechnung der Lernraten. [ü°•](https://ruder.io/optimizing-gradient-descent/)
  
  - SGD: Klassischer Gradientenabstiegsalgorithmus mit konfigurierbarer Stapelgr√∂√üe.
  
  - L-BFGS: Implementierung des [Broyden-Fletcher-Goldfarb-Shanno-Algorithmus](https://en.wikipedia.org/wiki/Broyden%E2%80%93Fletcher%E2%80%93Goldfarb%E2%80%93Shanno_algorithm) f√ºr begrenzten Speicher, ein Quasi-Newton-Verfahren, das eine Sch√§tzung der inversen [Hesse-Matrix](https://de.wikipedia.org/wiki/Hesse-Matrix) (Ableitungen zweiter Ordnung) zur Aktualisierung der Gewichte verwendet. Konvergiert sehr schnell f√ºr kleinere Datens√§tze. Dieser Solver besitzt keine Lernkurve.

- **Maximale Anzahl von Epochen:**
  Das Training wird nach Erreichen dieser Anzahl von Epochen oder nach Erreichen der angegebenen Toleranz beendet.

- **Toleranz:**
  Wenn sich das Training mindestens 10 Epochen lang nicht um diesen Deltawert verbessert, gilt das Training als beendet.

- **Zufallswert:**
  Der Seed-Wert f√ºr die Zufallszahlengenerierung, der f√ºr die Gewichte und die Bias-Initialisierung sowie f√ºr das Batch Sampling verwendet wird. Wenn hier ein ganzzahliger Wert eingestellt wird, f√ºhrt dies zu reproduzierbaren Ergebnissen.

- **L2-Penalty:**
  Der Regularisierungsparameter f√ºr die Ridge-Regression, der verwendet wird, um gro√üe Gewichte und Overfitting zu verhindern, indem der quadrierte Betrag der Koeffizienten als Penalty zur Verlustfunktion hinzugef√ºgt wird. Gro√üe L2-Parameterwerte f√ºhren zu Underfitting. [ü°•](https://towardsdatascience.com/l1-and-l2-regularization-methods-ce25e7fc831c?gi=273b9364d0a7)

- **Momentum:**
  F√ºgt dem Gradientenabstieg einen Momentum-Term hinzu, indem ein exponentiell gewichteter Mittelwert addiert wird, der bewirkt, dass die Gewichtsaktualisierungen in Richtung eines globalen Parameter-Minimums beschleunigt werden und verhindert, dass man in lokalen Minima stecken bleibt. 0,9 ist ein typischer Wert.

- **Batch-Gr√∂√üe:**
  Gr√∂√üe der Minibatches f√ºr die stochastischen Solver (SGD und Adam). "auto" w√§hlt das Minimum aus 200 oder der Gesamtzahl der Samples. Eine Gr√∂√üe von 1 entspricht einem stochastischen Gradientenabstieg mit Gewichtsaktualisierungen nach jedem pr√§sentierten Sample. Eine Batch-Gr√∂√üe, die alle Samples umfasst, entspricht dem Batch-Gradientenabstiegs-Algorithmus, bei dem die Gewichte nach der Pr√§sentation aller Samples aktualisiert werden. Die Verwendung von Minibatches (zwischen 1 und allen Stichproben) ist normalerweise der stabilste Ansatz.

- **Lernrate:**
  Konstante Lernrate f√ºr stochastische Solver, die die Schrittgr√∂√üe beim Aktualisieren der Gewichte steuert.

### Auswertung

Nach Abschluss des Trainings des Modells stehen eine Reihe von Auswertungsm√∂glichkeiten zur Verf√ºgung:

#### Modell testen

Stellt eine Punktwolke aus den realen und den vorhergesagten Werten im 3D-Raum dar. Diese Option ist nur f√ºr zweidimensionale Eingabedaten verf√ºgbar.

#### Verlustkurve

Zeichnet ein 2D-Diagramm, das den Verlauf der Verluste √ºber den Trainingszeitraum anzeigt.

#### Fehlerkurve

Stellt ein 2D-Diagramm der Differenz zwischen den Zieldaten und den Vorhersagen dar. Trainings- und Testdaten werden getrennt dargestellt.

#### Statistiken

Berechnet eine Reihe von relevanten statistischen Eigenschaften, getrennt nach Trainings- und Testdaten. Dazu geh√∂ren der R^2^-Score, minimale und maximale Fehlerwerte, absoluter mittlerer quadratischer Fehler, RMS-Fehler, usw.

> Der **R^2^-Score**, auch [Bestimmtheitsma√ü](https://de.wikipedia.org/wiki/Bestimmtheitsma%C3%9F), genannt  "[...] stellt den Anteil der Varianz (von y) dar, der durch die unabh√§ngigen Variablen im Modell erkl√§rt wurde. [...] Es ist also ein Ma√ü daf√ºr, wie gut unbekannte Stichproben durch den Anteil der erkl√§rten Varianz durch das Modell vorhergesagt werden k√∂nnen."
> Die Implementierung des R^2^-Scores in scikit-learn ist wie folgt definiert:

> $$
> R^2(y,\hat y_i) = 1 - \frac{\sum_{i=1}^{n}(y_i-\hat y_i)^2}{\sum_{i=1}^{n}(y_i-\bar y)^2}
> $$

> wobei $\bar y=\frac 1 n \sum_{i=1}^{n}y_i$ und $\sum_{i=1}^{n}(y_i-\hat y_i)^2=\sum_{i=1}^{n}\epsilon_i^2$. 
> 
> Dabei ist $\hat y_i$ der vorhergesagte Wert des $i$-ten Samples und $y_i$ der zugeh√∂rige tats√§chliche Wert f√ºr eine Gesamtheit von $n$ Samples. [ü°•](https://scikit-learn.org/stable/modules/model_evaluation.html#r2-score)

Der R^2^-Score reicht von 0 bis 1, kann aber auch negativ sein, wenn der Score aus Daten berechnet wird, die nicht zum Trainieren des Netzwerks verwendet wurden.

Die gleiche Berechnung des R^2^-Scores gilt f√ºr die Trendlinienfunktion in Microsoft Excel.

#### Gewichte & Bias

Gibt eine Tabelle mit allen Gewichten im Netzwerk und eine Tabelle mit den Bias-Werten pro Neuron aus.

Die Gewichts- und Bias-Matrizen k√∂nnen aus dem Dialog heraus in einer Excel-Datei gespeichert werden.

### Speichern

√ñffnet einen Speicherdialog, um das trainierte Modell als PMML-Datei f√ºr die sp√§tere Verwendung in anderer Software zu exportieren.

## Einschr√§nkungen

Neuronale Netze gibt es in einer gro√üen Vielfalt von Typen und Anwendungsszenarien. Dieses Tool bietet nur die Funktionalit√§t f√ºr eine bestimmte Klasse von Modellen, das Multilayer-Perceptron. Dieses wird auch oft f√ºr Klassifizierungsprobleme verwendet, allerdings funktioniert dieses Tool nur f√ºr Regressionsprobleme.

Die Eingabedaten k√∂nnen eine beliebige Anzahl von Dimensionen haben, die Ausgabe ist jedoch immer eindimensional, da dies das am h√§ufigsten verwendete Anwendungsszenario ist. Da dieses Tool auf die MLPRegressor-Methode aus der scikit-learn-Bibliothek zur√ºckgreift, ist die Implementierung von mehr als einer Ausgabe derzeit nicht m√∂glich.

Aufgrund der relativ kleinen Datens√§tze und der internen seriellen Verarbeitung ist GPU-Beschleunigung f√ºr dieses Tool (oder scikit-learn im Allgemeinen) nicht verf√ºgbar. Schnelle CPU-Taktraten helfen, die Trainingszeit zu verringern.

Die Modelloptimierung ist aufgrund der verwendeten MLPRegressor-Methode stark eingeschr√§nkt. Es ist kein Pruning oder Dropout verf√ºgbar. Dennoch sollte die Anpassung der Modellparameter in den meisten F√§llen zu zufriedenstellenden Ergebnissen f√ºhren.

Dieses Tool bietet keine Funktionen zur Datenvorverarbeitung, abgesehen von der Skalierung der Werte auf 0 bis 1. Der Benutzer ist f√ºr die Bereinigung des Datensatzes und die √úberpr√ºfung auf fehlerhafte Datenpunkte verantwortlich.

## Fehlerbehebung

Die meisten Anwendungsfehler sollten vom Tool selbst abgefangen werden und das Problem √ºber eine Warnmeldung erkl√§ren. Dazu geh√∂ren:

- Nicht √ºbereinstimmende Spalten- und Zeilenzahl in Trainings- und Testdatens√§tzen oder nicht gen√ºgend Spalten

- Leere oder besch√§digte Datens√§tze.

- Leere Felder in der Parameterkonfiguration

- Parameterkonfigurationen mit dem falschen Datentyp

Wenn die **Modellinitialisierung** fehlschl√§gt, liegt dies h√∂chstwahrscheinlich an der Parameterkonfiguration. Bitte √ºberpr√ºfen Sie die Parameterkonfiguration auf korrekte Datentypen. Verwenden Sie als Dezimaltrennzeichen einen Punkt, kein Komma.

Wenn die **Modellanpassung** fehlschl√§gt, wird dies h√∂chstwahrscheinlich durch ein Problem innerhalb des Datensatzes verursacht.
